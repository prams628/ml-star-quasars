{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import array, unique, log2, inf, append\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../catalog1/cat1.csv'\n",
    "df = read_csv(file_path)\n",
    "df.head()\n",
    "y = array(df['class'])\n",
    "# df = df.rename(columns={\"class\": \"label\"})\n",
    "if 'cat2.csv' in file_path:\n",
    "    df.drop(\"Unnamed: 0.1\", axis=1, inplace=True)\n",
    "df.drop([\"Unnamed: 0\", \"galex_objid\", \"sdss_objid\", \"class\", \"spectrometric_redshift\", \"pred\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(y):\n",
    "    if len(unique(y)) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(y):\n",
    "    unique_classes, counts_unique_classes = unique(y, return_counts=True)\n",
    "\n",
    "    index = counts_unique_classes.index(max(counts_unique_classes))\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(X, y):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    #n_columns = len(X[0])\n",
    "    for column_index in range(len(X[0])):  \n",
    "        potential_splits[column_index] = []\n",
    "        values = X[:, column_index]\n",
    "        unique_values = unique(values)\n",
    "\n",
    "        for index in range(len(unique_values)):\n",
    "            if index != 0:\n",
    "                current_value = unique_values[index]\n",
    "                previous_value = unique_values[index - 1]\n",
    "                potential_split = (current_value + previous_value) / 2\n",
    "                \n",
    "                potential_splits[column_index].append(potential_split)\n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, split_column, split_value):\n",
    "    \n",
    "    split_column_values = X[:, split_column]\n",
    "    data_below = data_above = array([])\n",
    "#     print(\"len(X) in function split_data:\", len(X))\n",
    "    for index in range(len(X) - 1):\n",
    "        if split_column_values[index] <= split_value:\n",
    "            data_below = append(data_below, append(X[index], y[index]))\n",
    "        else:\n",
    "            data_above = append(data_above, append(X[index], y[index]))\n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(data):\n",
    "    \n",
    "    print(data)\n",
    "    label_column = data[:, -1]\n",
    "    _, counts = unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -log2(probabilities))\n",
    "     \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overall_entropy(data_below, data_above):\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_entropy =  (p_data_below * calculate_entropy(data_below) \n",
    "                      + p_data_above * calculate_entropy(data_above))\n",
    "    \n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(X, y, potential_splits):    \n",
    "    overall_entropy = inf\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(X, y, split_column=column_index, split_value=value)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(X, y, column_headers, max_depth, counter=0, min_samples=2):\n",
    "    \n",
    "#     # data preparations\n",
    "#     if counter == 0:\n",
    "#         global COLUMN_HEADERS\n",
    "#         COLUMN_HEADERS = df.columns\n",
    "#         data = df.values\n",
    "#     else:\n",
    "#         data = df   \n",
    "        \n",
    "    if (check_purity(y)) or (len(X) < min_samples) or (counter == max_depth):\n",
    "        classification = classify_data(y)\n",
    "        \n",
    "        return classification\n",
    "\n",
    "    \n",
    "    # recursive part\n",
    "    else:    \n",
    "        counter += 1\n",
    "\n",
    "        # helper functions \n",
    "        potential_splits = get_potential_splits(X, y)\n",
    "        split_column, split_value = determine_best_split(X, y, potential_splits)\n",
    "        data_below, data_above = split_data(X, y, split_column, split_value)\n",
    "    \n",
    "        feature_name = column_headers[split_column]\n",
    "        question = \"{} <= {}\".format(feature_name, split_value)\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        # find answers (recursion)\n",
    "        yes_answer = decision_tree_algorithm(data_below, counter, min_samples, max_depth)\n",
    "        no_answer = decision_tree_algorithm(data_above, counter, min_samples, max_depth)\n",
    "        \n",
    "        # If the answers are the same, then there is no point in asking the qestion.\n",
    "        # This could happen when the data is classified even though it is not pure\n",
    "        # yet (min_samples or max_depth base case).\n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(X) in function split_data: 454\n",
      "[15.84910011 15.63408089 16.076437   16.29909706 16.52137756  0.09988927\n",
      "  0.07783304  0.05384454  0.04001226  0.02976177 16.00978088 16.12462044\n",
      "  0.16068077  0.3757     -0.06665611 -0.28931618 -0.51159668  0.21501923\n",
      " -0.22733688 -0.44999695 -0.67227745 -0.44235611 -0.66501617 -0.88729668\n",
      " -0.22266006 -0.44494057 -0.2222805  -0.11483955 -0.27552032 -0.49053955\n",
      " -0.04818344  0.17447662  0.39675713  0.        ]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-80bd983a495d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecision_tree_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_headers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-45-8cb6b8f4ea1b>\u001b[0m in \u001b[0;36mdecision_tree_algorithm\u001b[0;34m(X, y, column_headers, max_depth, counter, min_samples)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# helper functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mpotential_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_potential_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0msplit_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetermine_best_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpotential_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mdata_below\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_above\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-e37f84679037>\u001b[0m in \u001b[0;36mdetermine_best_split\u001b[0;34m(X, y, potential_splits)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpotential_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcolumn_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mdata_below\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_above\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mcurrent_overall_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_overall_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_below\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_above\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcurrent_overall_entropy\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0moverall_entropy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-e7b91d19f080>\u001b[0m in \u001b[0;36mcalculate_overall_entropy\u001b[0;34m(data_below, data_above)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mp_data_above\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_above\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     overall_entropy =  (p_data_below * calculate_entropy(data_below) \n\u001b[0m\u001b[1;32m      8\u001b[0m                       + p_data_above * calculate_entropy(data_above))\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-47-7ae63a6cd71f>\u001b[0m in \u001b[0;36mcalculate_entropy\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlabel_column\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_column\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_counts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "tree = decision_tree_algorithm(X_train, y_train, column_headers=df.columns, max_depth=3)\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((454, 33), (195, 33))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "    # ask question\n",
    "    if example[feature_name] <= float(value):\n",
    "        answer = tree[question][0]\n",
    "    else:\n",
    "        answer = tree[question][1]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u               18.536404\n",
      "g               18.440216\n",
      "r               18.271149\n",
      "i               18.369190\n",
      "z               18.420809\n",
      "extinction_u     0.075586\n",
      "extinction_g     0.058896\n",
      "extinction_r     0.040744\n",
      "extinction_i     0.030277\n",
      "extinction_z     0.022521\n",
      "nuv_mag         19.023506\n",
      "fuv_mag         19.976627\n",
      "label            1.000000\n",
      "nuv-u            0.487103\n",
      "nuv-g            0.583290\n",
      "nuv-r            0.752357\n",
      "nuv-i            0.654316\n",
      "nuv-z            0.602697\n",
      "u-g              0.096188\n",
      "u-r              0.265255\n",
      "u-i              0.167213\n",
      "u-z              0.115595\n",
      "g-r              0.169067\n",
      "g-i              0.071026\n",
      "g-z              0.019407\n",
      "r-i             -0.098042\n",
      "r-z             -0.149660\n",
      "i-z             -0.051619\n",
      "fuv-nuv         -0.953121\n",
      "fuv-u           -1.440224\n",
      "fuv-g           -1.536411\n",
      "fuv-r           -1.705479\n",
      "fuv-i           -1.607437\n",
      "fuv-z           -1.555819\n",
      "Name: 636, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.9835529327393"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = test.iloc[0]\n",
    "print(example)\n",
    "classify_example(example, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(df, tree):\n",
    "\n",
    "    df[\"classification\"] = df.apply(classify_example, axis=1, args=(tree,))\n",
    "    df[\"classification_correct\"] = df[\"classification\"] == df[\"label\"]\n",
    "    \n",
    "    accuracy = df[\"classification_correct\"].mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pramod/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/pramod/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = calculate_accuracy(test, tree)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14982"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "454 * 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
