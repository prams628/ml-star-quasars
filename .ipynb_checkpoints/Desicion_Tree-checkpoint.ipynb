{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from numpy import array, unique, log2, inf, append, where\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../cat1.csv'\n",
    "df = read_csv(file_path)\n",
    "df.head()\n",
    "y = array(df['class'])\n",
    "# df = df.rename(columns={\"class\": \"label\"})\n",
    "if 'cat2.csv' in file_path:\n",
    "    df.drop(\"Unnamed: 0.1\", axis=1, inplace=True)\n",
    "df.drop([\"Unnamed: 0\", \"galex_objid\", \"sdss_objid\", \"class\", \"spectrometric_redshift\", \"pred\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array(df)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_purity(y):\n",
    "    if len(unique(y)) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_data(y):\n",
    "    unique_classes, unique_classes_counts = unique(y, return_counts=True)\n",
    "\n",
    "    index = where(unique_classes_counts == max(unique_classes_counts))[0][0]\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_splits(X, y):\n",
    "    \n",
    "    possible_splits = {}\n",
    "    col_index = 0\n",
    "    while col_index < len(X[0]):    \n",
    "        possible_splits[col_index] = []\n",
    "        values = X[:, col_index]\n",
    "        unique_vals = unique(values)\n",
    "        \n",
    "        index = 0\n",
    "        for index in range(len(unique_vals)):\n",
    "            if index != 0:\n",
    "                curr_val = unique_vals[index]\n",
    "                prev_val = unique_vals[index - 1]\n",
    "                possible_split = (curr_val + prev_val) / 2\n",
    "                possible_splits[col_index].append(possible_split)\n",
    "            \n",
    "        col_index+=1\n",
    "    return possible_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y, split_column, split_value):\n",
    "    \n",
    "    no_of_columns = len(X[0]) + 1\n",
    "    split_column_values = X[:, split_column]\n",
    "    data_below = data_above = array([]).reshape(0, no_of_columns)\n",
    "#     print(\"len(X) in function split_data:\", len(X))\n",
    "    for index in range(len(X)):\n",
    "        temp = array(append(X[index], y[index])).reshape(1, no_of_columns)\n",
    "        if split_column_values[index] <= split_value:\n",
    "            data_below = append(data_below, temp, axis=0)\n",
    "        else:\n",
    "            data_above = append(data_above, temp, axis=0)\n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(data):\n",
    "    \n",
    "#     print(data)\n",
    "    label_column = data[:, -1]\n",
    "    _, counts = unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -log2(probabilities))\n",
    "     \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_overall_entropy(data_below, data_above):\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_entropy =  (p_data_below * entropy(data_below) \n",
    "                      + p_data_above * entropy(data_above))\n",
    "    \n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_best_split(X, y, possible_splits):    \n",
    "    overall_entropy = inf\n",
    "    for column_index in possible_splits:\n",
    "        for value in possible_splits[column_index]:\n",
    "            data_below, data_above = split_data(X, y, split_column=column_index, split_value=value)\n",
    "            curr_overall_entropy = cal_overall_entropy(data_below, data_above)\n",
    "\n",
    "            if curr_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = curr_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(X, y, column_headers, max_depth, counter=0, min_samples=2): \n",
    "        \n",
    "    if (check_purity(y)) or (len(X) < min_samples) or (counter == max_depth):\n",
    "        classification = classify_data(y)\n",
    "        \n",
    "        return classification\n",
    "\n",
    "    \n",
    "    # recursive part\n",
    "    else:    \n",
    "        counter += 1\n",
    "#         print(counter)\n",
    "\n",
    "        # helper functions \n",
    "        possible_splits = get_potential_splits(X, y)\n",
    "        split_column, split_value = determine_best_split(X, y, possible_splits)\n",
    "        data_below, data_above = split_data(X, y, split_column, split_value)\n",
    "    \n",
    "        feature_name = column_headers[split_column]\n",
    "        question = \"column_{} <= {}\".format(split_column, split_value)\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        # find answers (recursion)\n",
    "        yes_answer = decision_tree(data_below[:, :-1], data_below[:, -1], column_headers, max_depth, counter, min_samples)\n",
    "        no_answer = decision_tree(data_above[:, :-1], data_above[:, -1], column_headers, max_depth, counter, min_samples)\n",
    "        \n",
    "        # If the answers are the same, then there is no point in asking the qestion.\n",
    "        # This could happen when the data is classified even though it is not pure\n",
    "        # yet (min_samples or max_depth base case).\n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'column_23 <= -0.040340900421199005': [{'column_22 <= 0.0194654464721505': [0.0,\n",
      "                                                                             1.0]},\n",
      "                                        {'column_13 <= 1.29900455474855': [1.0,\n",
      "                                                                           {'column_25 <= 1.2913246154785498': [1.0,\n",
      "                                                                                                                0.0]}]}]}\n"
     ]
    }
   ],
   "source": [
    "tree = decision_tree(X_train, y_train, column_headers=df.columns, max_depth=3)\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_example(example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")\n",
    "    x = int(feature_name.split(\"_\")[1])\n",
    "    \n",
    "    # ask question\n",
    "    if example[x] <= float(value):\n",
    "        answer = tree[question][0]\n",
    "    else:\n",
    "        answer = tree[question][1]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_test, tree):\n",
    "    predictions = array([])\n",
    "    for example in X_test:\n",
    "        predictions = append(predictions, classify_example(example, tree))\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.61      0.73        18\n",
      "          1       0.96      0.99      0.98       177\n",
      "\n",
      "avg / total       0.96      0.96      0.96       195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = predict(X_test, tree)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
